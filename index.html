<!Doctype html>
<html lang="en">
    <head>
        <title>ChronoTailor: Harnessing Attention Guidance for Fine-Grained Video Virtual Try-On</title>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="author" content="Jinjuan Wang, Wenzhang Sun, Ming Li, et al.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
<!--        <link rel="icon" type="image/png" href="data/bunny.png"/>-->

          <link rel="stylesheet" href="static/css/bulma.min.css">
<!--          <link rel="stylesheet" href="static/css/bulma-carousel.min.css">-->
<!--          <link rel="stylesheet" href="static/css/bulma-slider.min.css">-->
<!--          <link rel="stylesheet" href="static/css/fontawesome.all.min.css">-->
<!--          <link rel="stylesheet"-->
<!--          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">-->
<!--          <link rel="stylesheet" href="static/css/index.css">-->


        <link rel="stylesheet" type="text/css" href="style_project_page.css?cache=7754391418498779889">
        <link href="https://fonts.googleapis.com/css?family=Arvo|Roboto&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        <link rel="stylesheet" href="https://unpkg.com/@glidejs/glide/dist/css/glide.core.min.css">
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="https://unpkg.com/@glidejs/glide"></script>

        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

        <style type="text/css">
            .side-text {
                width:60%;
                display:inline-block;
                vertical-align:top;
            }
            .side-image {
                width: 38%;
                display: inline-block;
                vertical-align: top;
            }
            .controls {
                margin-bottom: 10px;
            }
            .left-controls {
                display: inline-block;
                vertical-align: top;
                width: 80%;
            }
            .right-controls {
                display: inline-block;
                vertical-align: top;
                width: 19%;
                text-align: right;
            }
            .render_window {
                display: inline-block;
                vertical-align: middle;
                box-shadow: 1px 0px 5px black;
                margin-right: 10px;
                margin-bottom: 10px;
                width: calc(33% - 10px);
            }
            .progress {
                background: #666;
                position: relative;
                height: 5px;
                margin-bottom: -5px;
                display: none;
            }
            .glide__slide:hover {cursor: grab;}
            .glide__slide:active {cursor: grabbing;}
            .glide__slide img {width: 90%;}
            .glide__bullets {
                text-align: center;
            }
            .glide__bullet--active {
                color: #aaa; 
            }


            @media (max-width: 400px) {
                .render_window {
                    display: block;
                    width: 90%;
                    margin: 10px auto;
                }
            }
            @media (max-width: 700px) {
                .side-image {
                    display: block;
                    width: 80%;
                    margin: 10px auto;
                }
                .side-text {
                    display: block;
                    width: 100%;
                }
            }
        </style>
    </head>
    <body>
        <div class="section">
<!--            <img src="src\logo_image_final.jpg" style="width:40%;">-->
            
            <h1 class="project-title">
                ChronoTailor: Harnessing Attention Guidance for Fine-Grained Video Virtual Try-On
            </h1>
            
            <div class="authors">

                <a href="">
                    Jinjuan Wang <sup>1,\*</sup>
                </a>
                <a href="">
                    Wenzhang Sun <sup>2,\*</sup>
                </a>
                <a href="">
                    Ming Li <sup>1</sup>
                </a>
                <a href="">
                    Yun Zheng <sup>1</sup>
                </a>
                <a href="">
                    Fanyao Li <sup>1</sup>
                </a>
                <a href="">
                    Zhulin Tao <sup>1,\ dagger</sup>
                </a>
                <a href="">
                    Donglin Di <sup>2</sup>
                </a>
                <a href="">
                    Hao Li <sup>2</sup>
                </a>
                <a href="">
                    Chen Wei <sup>2</sup>
                </a>
                <a href="">
                    Xianglin Huang <sup>1</sup>
                </a>


            </div>

            <div class="affiliations">
                <span><sup>1</sup> 
                    <a href="https://www.cuc.edu.cn">
                    Communication University of China
                    </a>
                </span>

                <span><sup>2</sup> 
                    <a href="">
                    Li Auto
                    </a>
                </span>
            </div>

            <div class="project-conference">
                <!-- 会议信息可根据实际情况添加，如：CVPR 2025 -->
            </div>

            <div class="project-icons">
                <a href="#" id="paper-link">
                    <i class="fa fa-file"></i> <br/>
                    Paper
                </a>
                <a href="#" id="code-link">
                    <i class="fa fa-github"></i> <br/>
                    Code
                </a>
            </div>

            <div class="teaser-image">
                <img src="src\front.png" style="width:90%;">
                <p class="caption" align="center"><strong>ChronoTailor</strong> generates temporally consistent videos with fine-grained garment details. Visual comparisons with state-of-the-art methods showcase our framework's superiority in preserving fabric textures and motion continuity.
                </p>
            </div>

            
            <div class="section-title">Abstract</div>
            <div class="content">
                <p>Video virtual try-on aims to seamlessly replace the clothing of a person in a source video with a target garment. Despite significant progress in this field, existing approaches still struggle to maintain continuity and reproduce garment details.</p>
                <p>In this paper, we introduce ChronoTailor, a diffusion-based framework that generates temporally consistent videos while preserving fine-grained garment details. By employing a precise spatio-temporal attention mechanism to guide the integration of fine-grained garment features, ChronoTailor achieves robust try-on performance.</p>
                <p>First, ChronoTailor leverages region-aware spatial guidance to steer the evolution of spatial attention and employs an attention-driven temporal feature fusion mechanism to generate more continuous temporal features. This dual approach not only enables fine-grained local editing but also effectively mitigates artifacts arising from video dynamics.</p>
                <p>Second, ChronoTailor integrates multi-scale garment features to preserve low-level visual details and incorporates a garment-pose feature alignment to ensure temporal continuity during dynamic motion. Additionally, we collect StyleDress, a new dataset featuring intricate garments, varied environments, and diverse poses, offering advantages over existing public datasets, and will be publicly available for research. Extensive experiments show that ChronoTailor maintains spatio-temporal continuity and preserves garment details during motion, significantly outperforming previous methods.</p>
            </div>


            <div class="section-title">Overview of ChronoTailor</div>
            <div class="content">
                <p>
                    Our aim is to generate high-quality video virtual try-on results with fine-grained garment details and temporal consistency.
                    Our proposed <strong>ChronoTailor</strong> consists of three main components: <strong>Diffusion Pipeline, Spatio-Temporal Attention Adapter, and Garment-Pose Alignment Module</strong>.
                </p>

                <p>
                    Within the entire framework, the Spatio-Temporal Attention Adapter encodes garment and pose conditions into a unified feature space, integrating them through a hierarchical attention mechanism.
                    At each diffusion step, the encoded features and temporal context are fed into the <strong>Progressive Attention Integrator (PAI)</strong> to capture both spatial relationships of garment parts and temporal dynamics across frames. This process fine-tunes the diffusion model to generate try-on results that align with target garments and maintain motion continuity.
                    Additionally, the <strong>garment-pose alignment module</strong> uses a pre-trained pose estimation network to ensure that the generated clothing moves naturally with the human body during dynamic actions.
                </p>
                <img src="src\overview.png" style="width:90%;">
                <p class="caption" align="center"><strong>Overview of ChronoTailor.</strong> It consists of Diffusion Pipeline, Spatio-Temporal Attention Adapter, and Garment-Pose Alignment Module.
                    The adapter uses a coupling structure with Progressive Attention Integrator (PAI) to capture spatial-temporal relationships of garment features. The alignment module regularizes pose consistency in the feature space.
                </p> <br>

                <img src="src\pai.png" style="width:60%;">
                <p class="caption" align="center">
                    <strong>Details of Progressive Attention Integrator (PAI).</strong> Garment features \( F_g \) and pose-aware temporal features \( F_t \) are fused through multi-head attention, where spatio-temporal graphs are constructed to model both local details and frame-to-frame dependencies.
                </p>

                <div class="section-title">Visualization of Methods</div>

                <div class="glide1">
                    <div class="glide__bullets" data-glide-el="controls[nav]">
                        <button class="glide__bullet" data-glide-dir="=0">Comparison</button>
                        <button class="glide__bullet" data-glide-dir="=1">Temporal Consistency</button>
                        <button class="glide__bullet" data-glide-dir="=2">Garment Details</button>
                    </div>
                    <div class="glide__track" data-glide-el="track">
                        <ul class="glide__slides">
                            <li class="glide__slide"><img src="src/compa.png" style="width:70%;">
                                <p class="caption" align="center">
                                    <strong>Visual comparison with state-of-the-art methods.</strong> Samples from the StyleDress dataset show ChronoTailor's superiority in garment texture preservation and pose alignment compared to ControlNet, VideoTryOn, and T2I-Adapter.
                                </p>
                            </li>

                            <li class="glide__slide"><img src="src/temporal.png" style="width:60%;">
                                <p class="caption" align="center">
                                    <strong>Temporal consistency evaluation.</strong> Our method maintains smooth clothing motion during jumping and walking actions, while other methods exhibit flickering or shape distortion.
                                </p>
                            </li>

                            <li class="glide__slide"><img src="src/details.png" style="width:60%;">
                                <p class="caption" align="center">
                                    <strong>Fine-grained garment details.</strong> ChronoTailor reproduces intricate patterns, folds, and fabric textures, as shown in close-up comparisons with baseline models.
                                </p>
                            </li>

                        </ul>
                    </div>
                </div>

                <br>

            <div class="section-title">Quantitative Results</div>
            <div class="content">
                <img src="src\table.png" style="width:80%;">
                <p class="caption" align="center"><strong>Results on StyleDress and public datasets.</strong> The best results and the second best results are marked in green and blue respectively. ChronoTailor achieves significant improvements in PSNR, SSIM, and pose alignment metrics.
                </p>
            </div>



          <div class="section-title">BibTeX</div>
            <div class="container is-max-desktop content">
              <pre><code>@article{wang2025chronotailor,
  title={ChronoTailor: Harnessing Attention Guidance for Fine-Grained Video Virtual Try-On},
  author={Wang, Jinjuan and Sun, Wenzhang and Li, Ming and Zheng, Yun and Li, Fanyao and Tao, Zhulin and Di, Donglin and Li, Hao and Chen, Wei and Huang, Xianglin},
  journal={arXiv preprint arXiv:2506.05858},
  year={2025}
}
}</code></pre>
            </div>

</section>






        <script type="module">
            import * as THREE from "https://unpkg.com/three@0.127.0/build/three.module.js";
            import {OrbitControls} from "https://unpkg.com/three@0.127.0/examples/jsm/controls/OrbitControls.js";
            import {OBJLoader} from "https://unpkg.com/three@0.127.0/examples/jsm/loaders/OBJLoader.js";

            // Render the predictions
            function random_choice(arr, n) {
                var index_set = {};
                var choice = [];
                while (choice.length < n) {
                    var idx = Math.floor(Math.random() * arr.length);
                    if (index_set[idx] !== undefined) {
                        continue;
                    }
                    index_set[idx] = 0;
                    choice.push(idx);
                }

                return choice.map(x => arr[x]);
            }

            function progress_bar() {
                var el = document.createElement("div");
                el.classList.add("progress");

                return {
                    domElement: el,
                    update: function (percent) {
                        percent = Math.min(1, Math.max(0, percent));
                        el.style.display = "block";
                        el.style.width = Math.round(percent * 100) + "%";
                    },
                    hide: function () {
                        el.style.display = "none";
                    }
                };
            }

            function reset_checkboxes(checkboxes) {
                Array.prototype.forEach.call(checkboxes, function (c) {
                    c.checked = false;
                });
                checkboxes[0].checked = true;
            }

            function show_object(el, prefix, N) {
                const scene = new THREE.Scene();
                const renderer = new THREE.WebGLRenderer();
                const camera = new THREE.PerspectiveCamera(75, 1, 0.1, 1000);
                const controls = new OrbitControls(camera, renderer.domElement);

                camera.position.set(0.5, 0.5, 0.5);
                controls.target.set(0, 0, 0);
                controls.autoRotate = true;
                controls.autoRotateSpeed = 4;
                scene.background = new THREE.Color("white");
                var size = el.dataset.size;
                renderer.setSize(size, size);
                var progress = progress_bar();
                el.appendChild(progress.domElement);
                el.appendChild(renderer.domElement);

                const amb_light = new THREE.AmbientLight(0x606060); // soft white light
                scene.add(amb_light);
                const hem_light = new THREE.HemisphereLight(0xffffbb, 0x080820, 0.5);
                scene.add(hem_light);

                const colors = [
                    0x1f77b4,
                    0xaec7e8,
                    0xff7f0e,
                    0xffbb78,
                    0x2ca02c,
                    0x98df8a,
                    0xd62728,
                    0xff9896,
                    0x9467bd,
                    0xc5b0d5,
                    0x8c564b,
                    0xc49c94,
                    0xe377c2,
                    0xf7b6d2,
                    0x7f7f7f,
                    0xc7c7c7,
                    0xbcbd22,
                    0xdbdb8d,
                    0x17becf,
                    0x9edae5
                ];
                var previous_canvas_size = size;
                function animate() {
                    requestAnimationFrame(animate);
                    if (el.offsetWidth != previous_canvas_size) {
                        previous_canvas_size = el.offsetWidth;
                        renderer.domElement.style.width = previous_canvas_size + "px";
                        renderer.domElement.style.height = previous_canvas_size + "px";
                    }

                    controls.update();
                    renderer.render(scene, camera);
                }

                const loader = new OBJLoader();
                var meshes = [];
                var progresses = [];
                var loaded = 0;
                function load_part(part_idx) {
                    progresses[part_idx] = 0;
                    loader.load(
                        prefix + "/part_00" + i + ".obj",
                        function (object) {
                            var g = object.children[0].geometry;
                            var m = new THREE.MeshLambertMaterial({color: colors[part_idx]});
                            m.transparent = true;
                            var mesh = new THREE.Mesh(g, m);
                            meshes[part_idx] = mesh;
                            scene.add(mesh);

                            loaded++;
                            if (loaded == N) {
                                progress.hide();
                            }
                        },
                        function (event) {
                            progresses[part_idx] = event.loaded / event.total;
                            var total_progress = 0;
                            for (var i=0; i<progresses.length; i++) {
                                total_progress += progresses[i] / progresses.length;
                            }
                            progress.update(total_progress);
                        }
                    )
                }
                for (var i=0; i<N; i++) {
                    load_part(i);
                }
                animate();

                return {
                    meshes: meshes,
                    show: function (indices) {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 0.5;
                            //meshes[i].visible = false;
                        }
                        for (var i=0; i<indices.length; i++) {
                            meshes[indices[i]].material.opacity = 1;
                            //meshes[indices[i]].visible = true;
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 1;
                            //meshes[i].visible = true;
                        }
                    },
                    set_size: function(width, height) {
                        renderer.setSize(width, height);
                    }
                };
            }

            function show_group(elements, objects, N) {
                var controls = [];
                for (var i=0; i<objects.length; i++) {
                    controls.push(show_object(elements[i], objects[i], N));
                }

                return {
                    controls: controls,
                    show: function (indices) {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show(indices);
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show_all();
                        }
                    }
                };
            }

            // Garment Models (示例链接，需替换为实际模型地址)
            var garments = [
                "https://example.com/garments/dress_01",
                "https://example.com/garments/shirt_02",
                "https://example.com/garments/coat_03"
            ];
            var garment_control = show_group(
                document.getElementById("garments").getElementsByClassName("render_window"),
                [garments[0], garments[1], garments[2]],
                8
            );
            var garment_checkboxes = document.querySelectorAll("#garments .controls input");
            reset_checkboxes(garment_checkboxes);
            document.querySelector("#garments .controls").addEventListener(
                "change",
                function (ev) {
                    if (ev.target.id == "garments_all") {
                        Array.prototype.filter.call(
                            garment_checkboxes,
                            (el) => el.id != "garments_all"
                        ).forEach(function (el) {el.checked = false;});
                    } else if (ev.target.checked) {
                        garment_checkboxes[0].checked = false;
                    }

                    var ids = new Set();
                    if (garment_checkboxes[0].checked) {
                        ids = new Set([0, 1, 2, 3, 4, 5, 6, 7]);
                    }
                    var part_ids = [1, 2, 0, 4, 3, 6, 5, 7];
                    for (var i=1; i<garment_checkboxes.length; i++) {
                        if (garment_checkboxes[i].checked) {
                            ids.add(part_ids[i-1]);
                        }
                    }

                    garment_control.show(Array.from(ids));
                }
            );
            document.querySelector("#garments .controls button").addEventListener(
                "click",
                function (ev) {
                    reset_checkboxes(garment_checkboxes);
                    var new_garments = random_choice(garments, 3);
                    var render_windows = document.getElementById("garments").getElementsByClassName("render_window");
                    Array.prototype.forEach.call(render_windows, function (r) {r.innerHTML = "";});
                    garment_control = show_group(
                        render_windows,
                        new_garments,
                        8
                    );
                }
            );

            // Motion Models (示例链接，需替换为实际模型地址)
            var motions = [
                "https://example.com/motions/walking",
                "https://example.com/motions/jumping",
                "https://example.com/motions/dancing"
            ];
            var motion_control = show_group(
                document.getElementById("motions").getElementsByClassName("render_window"),
                [motions[0], motions[1], motions[2]],
                12
            );
            var motion_checkboxes = document.querySelectorAll("#motions .controls input");
            reset_checkboxes(motion_checkboxes);
            document.querySelector("#motions .controls").addEventListener(
                "change",
                function (ev) {
                    if (ev.target.id == "motions_all") {
                        Array.prototype.filter.call(
                            motion_checkboxes,
                            (el) => el.id != "motions_all"
                        ).forEach(function (el) {el.checked = false;});
                    } else if (ev.target.checked) {
                        motion_checkboxes[0].checked = false;
                    }

                    var ids = new Set();
                    if (motion_checkboxes[0].checked) {
                        ids = new Set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]);
                    }
                    var part_ids = [3, 4, 0, 1, 2, 7, 8, 5, 6, 11, 9, 10];
                    for (var i=1; i<motion_checkboxes.length; i++) {
                        if (motion_checkboxes[i].checked) {
                            ids.add(part_ids[i-1]);
                        }
                    }

                    motion_control.show(Array.from(ids));
                }
            );
            document.querySelector("#motions .controls button").addEventListener(
                "click",
                function (ev) {
                    reset_checkboxes(motion_checkboxes);
                    var new_motions = random_choice(motions, 3);
                    var render_windows = document.getElementById("motions").getElementsByClassName("render_window");
                    Array.prototype.forEach.call(render_windows, function (r) {r.innerHTML = "";});
                    motion_control = show_group(
                        render_windows,
                        new_motions,
                        12
                    );
                }
            );
        </script>
        <script>
            // Make the carousel for the comparisons
            var glide1 = new Glide(".glide1", {
                type: "carousel",
                startAt: 0,
                perView: 1,
                autoplay: 4000
            }).mount();
        </script>
        <script>
            // 保留其他轮播组件以备扩展
            var glide2 = new Glide(".glide2", {
                type: "carousel",
                startAt: 0,
                perView: 1,
                autoplay: 4000
            }).mount();
        </script>
        <script>
            var glide3 = new Glide(".glide3", {
                type: "carousel",
                startAt: 0,
                perView: 1,
                autoplay: 4000
            }).mount();
        </script>
    </body>
</html>
