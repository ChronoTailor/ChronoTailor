<!DOCTYPE html>
<html lang="en">
    <head>
        <title>ChronoTailor: Harnessing Attention Guidance for Fine-Grained Video Virtual Try-On</title>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="author" content="Jinjuan Wang, Wenzhang Sun, Ming Li, et al.">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel="stylesheet" href="static/css/bulma.min.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Arvo|Roboto&display=swap">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        <link rel="stylesheet" href="https://unpkg.com/@glidejs/glide/dist/css/glide.core.min.css">
        
        <link rel="stylesheet" type="text/css" href="style_project_page.css?cache=7754391418498779889">

        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="https://unpkg.com/@glidejs/glide"></script>

        <style type="text/css">
            .side-text {
                width:60%;
                display:inline-block;
                vertical-align:top;
            }
            .side-image {
                width: 38%;
                display: inline-block;
                vertical-align: top;
            }
            .controls {
                margin-bottom: 10px;
            }
            .left-controls {
                display: inline-block;
                vertical-align: top;
                width: 80%;
            }
            .right-controls {
                display: inline-block;
                vertical-align: top;
                width: 19%;
                text-align: right;
            }
            .render_window {
                display: inline-block;
                vertical-align: middle;
                box-shadow: 1px 0px 5px black;
                margin-right: 10px;
                margin-bottom: 10px;
                width: calc(33% - 10px);
            }
            .progress {
                background: #666;
                position: relative;
                height: 5px;
                margin-bottom: -5px;
                display: none;
            }
            .glide__slide:hover {cursor: grab;}
            .glide__slide:active {cursor: grabbing;}
            .glide__slide img {width: 90%;}
            
            /* 轮播导航圆点样式 */
            .glide__bullets {
                text-align: center;
                margin: 20px 0;
            }
            .glide__bullet {
                width: 12px;
                height: 12px;
                border-radius: 50%;
                background: #ddd;
                border: none;
                padding: 0;
                cursor: pointer;
                transition: all 0.3s ease;
                margin: 0 5px;
                box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            }
            .glide__bullet--active {
                background: #3B82F6; /* 主色调蓝色 */
                width: 16px;
                height: 16px;
            }
            .glide__bullet:hover:not(.glide__bullet--active) {
                background: #999;
                transform: scale(1.1);
            }

            @media (max-width: 400px) {
                .render_window {
                    display: block;
                    width: 90%;
                    margin: 10px auto;
                }
            }
            @media (max-width: 700px) {
                .side-image {
                    display: block;
                    width: 80%;
                    margin: 10px auto;
                }
                .side-text {
                    display: block;
                    width: 100%;
                }
            }
            
            .section-title {
                text-align: center;
                font-size: 24px;
                margin: 30px 0 20px;
                position: relative;
            }
            .section-title:after {
                content: '';
                display: block;
                width: 60px;
                height: 3px;
                background: #4a90e2;
                margin: 10px auto 0;
            }
            
            .video-container {
                position: relative;
                display: flex;
                justify-content: center;
            }
            .video-item {
                box-shadow: 0 4px 18px rgba(0,0,0,0.15);
                display: block;
                margin: 0 auto 15px;
                transition: all 0.3s;
            }
            .video-item:hover {
                transform: translateY(-5px);
                box-shadow: 0 10px 25px rgba(0,0,0,0.2);
            }
            .caption {
                font-size: 14px;
                line-height: 1.5;
                color: #333;
                margin: 10px 0;
            }
            .video-loading {
                position: absolute;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                display: flex;
                justify-content: center;
                align-items: center;
                background: rgba(0,0,0,0.7);
                z-index: 1;
            }
            .spinner {
                width: 40px;
                height: 40px;
                border: 4px solid rgba(255,255,255,0.1);
                border-left-color: #2ecc71;
                border-radius: 50%;
                animation: spin 1s linear infinite;
            }
            .video-fallback {
                display: none;
                flex-direction: column;
                justify-content: center;
                align-items: center;
                width: 100%;
                height: 100%;
                background: rgba(0,0,0,0.8);
                color: #fff;
                z-index: 2;
            }
            .video-fallback i {
                font-size: 3rem;
                margin-bottom: 10px;
                color: #2ecc71;
            }
            @keyframes spin {
                to { transform: rotate(360deg); }
            }
            @media (max-width: 768px) {
                .video-item {
                    width: 90% !important;
                }
                .glide__bullet {
                    width: 10px;
                    height: 10px;
                }
                .glide__bullet--active {
                    width: 14px;
                    height: 14px;
                }
                .caption {
                    font-size: 13px;
                }
            }
        </style>
    </head>
    <body>
        <div class="section">
            <h1 class="project-title">
                ChronoTailor: Harnessing Attention Guidance for Fine-Grained Video Virtual Try-On
            </h1>
            
            <div class="authors">
                <a href="">Jinjuan Wang <sup>1*</sup></a>
                <a href="">Wenzhang Sun <sup>2*</sup></a>
                <a href="">Ming Li <sup>1</sup></a>
                <a href="">Yun Zheng <sup>1</sup></a>
                <a href="">Fanyao Li <sup>1</sup></a>
                <a href="">Zhulin Tao <sup>1†</sup></a>
                <a href="">Donglin Di <sup>2</sup></a>
                <a href="">Hao Li <sup>2</sup></a>
                <a href="">Wei Chen <sup>2</sup></a>
                <a href="">Xianglin Huang <sup>1</sup></a>
            </div>

            <div class="affiliations">
                <span><sup>1</sup> <a href="https://www.cuc.edu.cn">Communication University of China</a></span>
                <span><sup>2</sup> <a href="">Li Auto</a></span>
            </div>

            <div class="project-icons">
                <a href="https://arxiv.org/abs/2506.05858" id="paper-link">
                    <i class="fa fa-file"></i> <br/>Paper
                </a>
                <a href="https://github.com/ChronoTailor/ChronoTailor/" id="code-link">
                    <i class="fa fa-github"></i> <br/>Code
                </a>
            </div>

            <div class="teaser-image">
                <img src="src\Fig1_00.png" style="width:90%;">
                <p class="caption" align="center"><strong>ChronoTailor</strong> excels at generating high-quality virtual try-ons for diverse garments, effectively maintaining visual coherence and preserving background details.</p>
            </div>

            <div class="section-title">Abstract</div>
            <div class="content">
                <p>Video virtual try-on aims to seamlessly replace the clothing of a person in a source video with a target garment. Despite significant progress in this field, existing approaches still struggle to maintain continuity and reproduce garment details.</p>
                <p>In this paper, we introduce ChronoTailor, a diffusion-based framework that generates temporally consistent videos while preserving fine-grained garment details. By employing a precise spatio-temporal attention mechanism to guide the integration of fine-grained garment features, ChronoTailor achieves robust try-on performance.</p>
                <p>First, ChronoTailor leverages region-aware spatial guidance to steer the evolution of spatial attention and employs an attention-driven temporal feature fusion mechanism to generate more continuous temporal features. This dual approach not only enables fine-grained local editing but also effectively mitigates artifacts arising from video dynamics.</p>
                <p>Second, ChronoTailor integrates multi-scale garment features to preserve low-level visual details and incorporates a garment-pose feature alignment to ensure temporal continuity during dynamic motion. Additionally, we collect StyleDress, a new dataset featuring intricate garments, varied environments, and diverse poses, offering advantages over existing public datasets, and will be publicly available for research. Extensive experiments show that ChronoTailor maintains spatio-temporal continuity and preserves garment details during motion, significantly outperforming previous methods.</p>
            </div>


            <div class="section-title">Overview of ChronoTailor</div>
            <div class="content">
                <p>ChronoTailor aims to generate temporally coherent virtual try-on videos while preserving fine-grained garment details.</p>
                <p>ChronoTailor  consists of two main components: (1) Spatial-Temporal Attention Guidance, which includes Region-Aware Spatial Guidance (RASG) that uses segmentation masks to guide spatial attention map evolution, and Attention-Driven Temporal Feature Fusion (ATFF), which employs an asymmetric cross-space attention mechanism using original features as queries and randomly fused other frame features as key-values to integrate temporal information effectively. </p>
                <p>(2) Multi-scale Garment-Pose Feature Alignment, which first applies Adaptive Multi-scale Feature Extraction (AMFE) to enhance low-level garment details, and then aligns garment features with pose features using Garment-Pose Feature Alignment (GPFA).</p>
                <img src="src\Fig2Model_00.png" style="width:90%;">
                <p class="caption" align="center"><strong>Architecture of the ChronoTailor.</strong> Spatial-Temporal Attention Guidance enables the acquisition of stable guidance for garment feature injection. Multi-scale Garment-Pose Feature Alignment, meanwhile, facilitates the capture of more precise garment information during motion.</p> <br>

                <img src="src\supp_styledress_00.png" style="width:60%;">
                <p class="caption" align="center"><strong>Sample pairs from the StyleDress.</strong></p>

            <div class="section-title">Visualization of Methods</div>
            <div class="glide1">
               <!-- 改为10个圆点导航按钮 -->
                <div class="glide__bullets" data-glide-el="controls[nav]">
                    <button class="glide__bullet glide__bullet--active" data-glide-dir="=0"></button>
                    <button class="glide__bullet" data-glide-dir="=1"></button>
                    <button class="glide__bullet" data-glide-dir="=2"></button>
                    <button class="glide__bullet" data-glide-dir="=3"></button>
                    <button class="glide__bullet" data-glide-dir="=4"></button>
                    <button class="glide__bullet" data-glide-dir="=5"></button>
                    <button class="glide__bullet" data-glide-dir="=6"></button>
                </div>
                <div class="glide__track" data-glide-el="track">
                    <ul class="glide__slides">
                        <li class="glide__slide"><img src="src/VIVID_00.png" style="width:70%;">
                            <p class="caption" align="center"><strong>Visual comparison of ours and other methods.</strong> Our method demonstrates superior capability in generating clearer texture details within the editing region, producing more plausible results that exhibit enhanced visual fidelity and structural coherence.</p>
                        </li>
                        
                        <li class="glide__slide"><img src="src/viton_00.png" style="width:60%;">
                            <p class="caption" align="center"><strong>Qualitative comparison on the VITON-HD dataset.</strong> </p>
                        </li>
                        <li class="glide__slide"><img src="src/Fig6_accessories_00.png" style="width:60%;">
                            <p class="caption" align="center"><strong>ChronoTailor effectively preserves information in non - edited regions.</strong> </p>
                        </li>

                        <li class="glide__slide"><img src="src/Fig8_inthewild_00.png" style="width:60%;">
                            <p class="caption" align="center"><strong>Qualitative results of our method on the StyleDress dataset.</strong> </p>
                        </li>

                        <li class="glide__slide"><img src="src/AMFE_00.png" style="width:60%;">
                            <p class="caption" align="center"><strong>Ablation study of Adaptive Multi-scale Feature Extraction. The upper garment try-on fully recovers two floral patterns, demonstrating ChronoTailor’s capability to preserve intricate textures and semantic details.</strong> </p>
                        </li>

                         <li class="glide__slide"><img src="src/ATFF_00.png" style="width:60%;">
                            <p class="caption" align="center"><strong>Ablation study of Attention-Driven Temporal Feature Fusion.</strong> </p>
                        </li>

                         <li class="glide__slide"><img src="src/RASG_00.png" style="width:60%;">
                            <p class="caption" align="center"><strong>Ablation study of Region-Aware Spatial Guidance.</strong>Our method balances attention between editing and non - editing regions. </p>
                        </li>
                    </ul>
                </div>
            </div>

            <br>
            <div class="section-title">More Results</div>
                <div class="glide">
                    <!-- 动态生成的轮播指示器（10个视频对应10个按钮） -->
                    <div class="glide__bullets" data-glide-el="controls[nav]" style="display: flex; justify-content: center; gap: 8px; margin: 15px 0;">
                        <button class="glide__bullet glide__bullet--active" data-glide-dir="=0"></button>
                        <button class="glide__bullet" data-glide-dir="=1"></button>
                        <button class="glide__bullet" data-glide-dir="=2"></button>
                        <button class="glide__bullet" data-glide-dir="=3"></button>
                        <button class="glide__bullet" data-glide-dir="=4"></button>
                        <button class="glide__bullet" data-glide-dir="=5"></button>
                        <button class="glide__bullet" data-glide-dir="=6"></button>
                        <button class="glide__bullet" data-glide-dir="=7"></button>
                        <button class="glide__bullet" data-glide-dir="=8"></button>
                        <button class="glide__bullet" data-glide-dir="=9"></button>
                    </div>
                    
                    <div class="glide__track" data-glide-el="track">
                        <ul class="glide__slides">
                            <!-- 视频1 -->
                            <li class="glide__slide">
                                <div class="video-container">
                                    <video data-src="src/6191.mp4" 
                                           class="video-item"
                                           style="width: 70%; border-radius: 8px;"
                                        <div class="video-fallback">
                                            <i class="fas fa-video"></i>
                                            <p>视频加载失败，请检查格式或路径</p>
                                        </div>
                                    </video>
                                    <div class="video-loading">
                                        <div class="spinner"></div>
                                    </div>
                                </div>
                                <p class="caption" align="center"><strong>Visual comparison of ours and other methods.</strong> Our method demonstrates superior capability in generating clearer texture details within the editing region, producing more plausible results that exhibit enhanced visual fidelity and structural coherence.</p>
                            </li>
                            
                            <!-- 视频2-10 保持原有结构 -->
                            <li class="glide__slide">
                                <div class="video-container">
                                    <video data-src="src/6192.mp4" 
                                           class="video-item"
                                           style="width: 60%; border-radius: 8px;"
                                        <div class="video-fallback">
                                            <i class="fas fa-video"></i>
                                            <p>视频加载失败，请检查格式或路径</p>
                                        </div>
                                    </video>
                                    <div class="video-loading">
                                        <div class="spinner"></div>
                                    </div>
                                </div>
                                <p class="caption" align="center"><strong>Qualitative comparison on the VITON-HD dataset.</strong> </p>
                            </li>
                            
                            <!-- 省略视频3-10的代码，结构与视频2类似 -->
                            
                        </ul>
                    </div>
                </div>
                
                <!-- 引入依赖 -->
                <link rel="stylesheet" href="https://unpkg.com/@glidejs/glide/dist/css/glide.core.min.css">
                <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
                <script src="https://unpkg.com/@glidejs/glide"></script>
                
                <script>
                    document.addEventListener('DOMContentLoaded', function() {
                        // 初始化图片轮播
                        const glide1 = new Glide('.glide1', {
                            type: 'carousel',
                            startAt: 0,
                            perView: 1,
                            autoplay: 5000,       // 5秒自动切换
                            animationDuration: 500,// 切换动画时长
                            gap: 20,              // 图片间距
                            keyboard: true,       // 启用键盘导航
                            touch: true           // 启用触摸滑动
                        });
                        
                        // 初始化视频轮播
                        const glide2 = new Glide('.glide', {
                            type: 'carousel',
                            startAt: 0,
                            perView: 1,
                            autoplay: 5000,
                            animationDuration: 500,
                            gap: 20,
                            keyboard: true,
                            touch: true
                        });
                        
                        glide1.mount();
                        glide2.mount();
                        
                        // 视频加载逻辑
                        const videos = document.querySelectorAll('.video-item');
                        videos.forEach(video => {
                            const src = video.getAttribute('data-src');
                            video.src = src;
                            
                            const loading = video.parentElement.querySelector('.video-loading');
                            const fallback = video.querySelector('.video-fallback');
                            
                            video.addEventListener('loadeddata', function() {
                                loading.style.display = 'none';
                            });
                            
                            video.addEventListener('error', function() {
                                loading.style.display = 'none';
                                fallback.style.display = 'flex';
                            });
                        });
                    });
                </script>
                <br>
          <div class="section-title">BibTeX</div>
            <div class="container is-max-desktop content">
              <pre><code>@article{wang2025chronotailor,
  title={ChronoTailor: Harnessing Attention Guidance for Fine-Grained Video Virtual Try-On},
  author={Wang, Jinjuan and Sun, Wenzhang and Li, Ming and Zheng, Yun and Li, Fanyao and Tao, Zhulin and Di, Donglin and Li, Hao and Chen, Wei and Huang, Xianglin},
  journal={arXiv preprint arXiv:2506.05858},
  year={2025}
}
}</code></pre>
            </div>

</section>






        <script type="module">
            import * as THREE from "https://unpkg.com/three@0.127.0/build/three.module.js";
            import {OrbitControls} from "https://unpkg.com/three@0.127.0/examples/jsm/controls/OrbitControls.js";
            import {OBJLoader} from "https://unpkg.com/three@0.127.0/examples/jsm/loaders/OBJLoader.js";

            // Render the predictions
            function random_choice(arr, n) {
                var index_set = {};
                var choice = [];
                while (choice.length < n) {
                    var idx = Math.floor(Math.random() * arr.length);
                    if (index_set[idx] !== undefined) {
                        continue;
                    }
                    index_set[idx] = 0;
                    choice.push(idx);
                }

                return choice.map(x => arr[x]);
            }

            function progress_bar() {
                var el = document.createElement("div");
                el.classList.add("progress");

                return {
                    domElement: el,
                    update: function (percent) {
                        percent = Math.min(1, Math.max(0, percent));
                        el.style.display = "block";
                        el.style.width = Math.round(percent * 100) + "%";
                    },
                    hide: function () {
                        el.style.display = "none";
                    }
                };
            }

            function reset_checkboxes(checkboxes) {
                Array.prototype.forEach.call(checkboxes, function (c) {
                    c.checked = false;
                });
                checkboxes[0].checked = true;
            }

            function show_object(el, prefix, N) {
                const scene = new THREE.Scene();
                const renderer = new THREE.WebGLRenderer();
                const camera = new THREE.PerspectiveCamera(75, 1, 0.1, 1000);
                const controls = new OrbitControls(camera, renderer.domElement);

                camera.position.set(0.5, 0.5, 0.5);
                controls.target.set(0, 0, 0);
                controls.autoRotate = true;
                controls.autoRotateSpeed = 4;
                scene.background = new THREE.Color("white");
                var size = el.dataset.size;
                renderer.setSize(size, size);
                var progress = progress_bar();
                el.appendChild(progress.domElement);
                el.appendChild(renderer.domElement);

                const amb_light = new THREE.AmbientLight(0x606060); // soft white light
                scene.add(amb_light);
                const hem_light = new THREE.HemisphereLight(0xffffbb, 0x080820, 0.5);
                scene.add(hem_light);

                const colors = [
                    0x1f77b4,
                    0xaec7e8,
                    0xff7f0e,
                    0xffbb78,
                    0x2ca02c,
                    0x98df8a,
                    0xd62728,
                    0xff9896,
                    0x9467bd,
                    0xc5b0d5,
                    0x8c564b,
                    0xc49c94,
                    0xe377c2,
                    0xf7b6d2,
                    0x7f7f7f,
                    0xc7c7c7,
                    0xbcbd22,
                    0xdbdb8d,
                    0x17becf,
                    0x9edae5
                ];
                var previous_canvas_size = size;
                function animate() {
                    requestAnimationFrame(animate);
                    if (el.offsetWidth != previous_canvas_size) {
                        previous_canvas_size = el.offsetWidth;
                        renderer.domElement.style.width = previous_canvas_size + "px";
                        renderer.domElement.style.height = previous_canvas_size + "px";
                    }

                    controls.update();
                    renderer.render(scene, camera);
                }

                const loader = new OBJLoader();
                var meshes = [];
                var progresses = [];
                var loaded = 0;
                function load_part(part_idx) {
                    progresses[part_idx] = 0;
                    loader.load(
                        prefix + "/part_00" + i + ".obj",
                        function (object) {
                            var g = object.children[0].geometry;
                            var m = new THREE.MeshLambertMaterial({color: colors[part_idx]});
                            m.transparent = true;
                            var mesh = new THREE.Mesh(g, m);
                            meshes[part_idx] = mesh;
                            scene.add(mesh);

                            loaded++;
                            if (loaded == N) {
                                progress.hide();
                            }
                        },
                        function (event) {
                            progresses[part_idx] = event.loaded / event.total;
                            var total_progress = 0;
                            for (var i=0; i<progresses.length; i++) {
                                total_progress += progresses[i] / progresses.length;
                            }
                            progress.update(total_progress);
                        }
                    )
                }
                for (var i=0; i<N; i++) {
                    load_part(i);
                }
                animate();

                return {
                    meshes: meshes,
                    show: function (indices) {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 0.5;
                            //meshes[i].visible = false;
                        }
                        for (var i=0; i<indices.length; i++) {
                            meshes[indices[i]].material.opacity = 1;
                            //meshes[indices[i]].visible = true;
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 1;
                            //meshes[i].visible = true;
                        }
                    },
                    set_size: function(width, height) {
                        renderer.setSize(width, height);
                    }
                };
            }

            function show_group(elements, objects, N) {
                var controls = [];
                for (var i=0; i<objects.length; i++) {
                    controls.push(show_object(elements[i], objects[i], N));
                }

                return {
                    controls: controls,
                    show: function (indices) {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show(indices);
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show_all();
                        }
                    }
                };
            }

            // Humans
            var humans = [
                "https://superquadrics.com/neural_parts/humans/50002_chicken_wings",
                "https://superquadrics.com/neural_parts/humans/50002_hips",
                "https://superquadrics.com/neural_parts/humans/50002_jiggle_on_toes",
                "https://superquadrics.com/neural_parts/humans/50002_jumping_jacks",
                "https://superquadrics.com/neural_parts/humans/50002_jumping_jacks_00038",
                "https://superquadrics.com/neural_parts/humans/50002_jumping_jacks_2",
                "https://superquadrics.com/neural_parts/humans/50002_knees",
                "https://superquadrics.com/neural_parts/humans/50004_punching",
                "https://superquadrics.com/neural_parts/humans/50004_running_on_spot",
                "https://superquadrics.com/neural_parts/humans/50004_running_on_spot_00220",
                "https://superquadrics.com/neural_parts/humans/50004_running_on_spot_2",
                "https://superquadrics.com/neural_parts/humans/50004_running_spot",
                "https://superquadrics.com/neural_parts/humans/50007_jumping_jacks",
                "https://superquadrics.com/neural_parts/humans/50009_chicken_wings",
                "https://superquadrics.com/neural_parts/humans/50009_jumping_jacks",
                "https://superquadrics.com/neural_parts/humans/50009_jumping_jacks_00140",
                "https://superquadrics.com/neural_parts/humans/50009_one_leg_jump",
                "https://superquadrics.com/neural_parts/humans/50009_one_leg_jump_00075",
                "https://superquadrics.com/neural_parts/humans/50009_shake_hips",
                "https://superquadrics.com/neural_parts/humans/50020_knees_00136",
                "https://superquadrics.com/neural_parts/humans/50021_knees",
                "https://superquadrics.com/neural_parts/humans/50021_knees_2",
                "https://superquadrics.com/neural_parts/humans/50021_knees_3",
                "https://superquadrics.com/neural_parts/humans/50021_knees_4",
                "https://superquadrics.com/neural_parts/humans/50021_knees_5",
                "https://superquadrics.com/neural_parts/humans/50021_knees_6",
                "https://superquadrics.com/neural_parts/humans/50021_knees_7",
                "https://superquadrics.com/neural_parts/humans/50021_one_leg_jump",
                "https://superquadrics.com/neural_parts/humans/50021_running_on_spot",
                "https://superquadrics.com/neural_parts/humans/50021_running_on_spot_2",
                "https://superquadrics.com/neural_parts/humans/50022_punching_00069",
                "https://superquadrics.com/neural_parts/humans/50022_shake_hips",
                "https://superquadrics.com/neural_parts/humans/50026_knees",
                "https://superquadrics.com/neural_parts/humans/50027_jumping_jacks",
                "https://superquadrics.com/neural_parts/humans/50027_jumping_jacks_2",
                "https://superquadrics.com/neural_parts/humans/50027_jumping_jacks_3",
                "https://superquadrics.com/neural_parts/humans/50027_jumping_jacks_4",
                "https://superquadrics.com/neural_parts/humans/50027_jumping_jacks_5",
            ];
            var human_control = show_group(
                document.getElementById("humans").getElementsByClassName("render_window"),
                [humans[0], humans[1], humans[2]],
                6
            );
            var human_checkboxes = document.querySelectorAll("#humans .controls input");
            reset_checkboxes(human_checkboxes);
            document.querySelector("#humans .controls").addEventListener(
                "change",
                function (ev) {
                    if (ev.target.id == "humans_all") {
                        Array.prototype.filter.call(
                            human_checkboxes,
                            (el) => el.id != "humans_all"
                        ).forEach(function (el) {el.checked = false;});
                    } else if (ev.target.checked) {
                        human_checkboxes[0].checked = false;
                    }

                    var ids = new Set();
                    if (human_checkboxes[0].checked) {
                        ids = new Set([0, 1, 2, 3, 4, 5]);
                    }
                    var part_ids = [1, 2, 0, 4, 3, 5];
                    for (var i=1; i<human_checkboxes.length; i++) {
                        if (human_checkboxes[i].checked) {
                            ids.add(part_ids[i-1]);
                        }
                    }

                    human_control.show(Array.from(ids));
                }
            );
            document.querySelector("#humans .controls button").addEventListener(
                "click",
                function (ev) {
                    reset_checkboxes(human_checkboxes);
                    var new_humans = random_choice(humans, 3);
                    var render_windows = document.getElementById("humans").getElementsByClassName("render_window");
                    Array.prototype.forEach.call(render_windows, function (r) {r.innerHTML = "";});
                    human_control = show_group(
                        render_windows,
                        new_humans,
                        6
                    );
                }
            );

            // Planes
            var planes = [
                "https://superquadrics.com/neural_parts/planes/10af5de930178a161596c26b5af806fe",
                "https://superquadrics.com/neural_parts/planes/1a32f10b20170883663e90eaf6b4ca52",
                "https://superquadrics.com/neural_parts/planes/1a6ad7a24bb89733f412783097373bdc",
                "https://superquadrics.com/neural_parts/planes/1b3c6b2fbcf834cf62b600da24e0965",
                "https://superquadrics.com/neural_parts/planes/1c26ecb4cd01759dc1006ed55bc1a3fc",
                "https://superquadrics.com/neural_parts/planes/284e6431669d46fd44797ce00623b3fd",
                "https://superquadrics.com/neural_parts/planes/2c3ba3f35c5d2b0ce77e43d0a92bdc06",
                "https://superquadrics.com/neural_parts/planes/315f523d0a924fb7ef70df8610b582b2",
                "https://superquadrics.com/neural_parts/planes/343a607d1604335fb4f192eea1889928",
                "https://superquadrics.com/neural_parts/planes/347d86d7001cef01232236eecec447b",
                "https://superquadrics.com/neural_parts/planes/351c9235749e398162147e00e97e28b5",
                "https://superquadrics.com/neural_parts/planes/3716ed4fa80dbf5f41392ab7a601818b",
                "https://superquadrics.com/neural_parts/planes/384e72f69e6f24404cb288947cda4a2c",
                "https://superquadrics.com/neural_parts/planes/440ac1b4ac3cbe114c3a35cee92bb95b",
                "https://superquadrics.com/neural_parts/planes/440e5ba74ac8124e9751c7a6f15617f4",
                "https://superquadrics.com/neural_parts/planes/48706d323b9041d5438a95791ca4064d",
                "https://superquadrics.com/neural_parts/planes/563cef4df464ddb1e153dd90dac45a6d",
                "https://superquadrics.com/neural_parts/planes/5c6590461085c93ea91e80f26309099e",
                "https://superquadrics.com/neural_parts/planes/60b5f5da40e0dd33579f6385fdd4245b",
                "https://superquadrics.com/neural_parts/planes/7b134f6573e7270fb0a79e28606cb167",
                "https://superquadrics.com/neural_parts/planes/92a83ecaa10e8d3f78e919a72d9a39e7",
                "https://superquadrics.com/neural_parts/planes/ed2aaca045fb1714cd4229f38ad0d015",
                "https://superquadrics.com/neural_parts/planes/f12eefbbefabe566ca8607f540cc62ba",
            ];
            var plane_control = show_group(
                document.getElementById("planes").getElementsByClassName("render_window"),
                [planes[7], planes[1], planes[2]],
                5
            );
            var plane_checkboxes = document.querySelectorAll("#planes .controls input");
            reset_checkboxes(plane_checkboxes);
            document.querySelector("#planes .controls").addEventListener(
                "change",
                function (ev) {
                    if (ev.target.id == "planes_all") {
                        Array.prototype.filter.call(
                            plane_checkboxes,
                            (el) => el.id != "planes_all"
                        ).forEach(function (el) {el.checked = false;});
                    } else if (ev.target.checked) {
                        plane_checkboxes[0].checked = false;
                    }

                    var ids = new Set();
                    if (plane_checkboxes[0].checked) {
                        ids = new Set([0, 1, 2, 3, 4]);
                    }
                    var part_ids = [4, 0, 3, 2, 1];
                    for (var i=1; i<plane_checkboxes.length; i++) {
                        if (plane_checkboxes[i].checked) {
                            ids.add(part_ids[i-1]);
                        }
                    }

                    plane_control.show(Array.from(ids));
                }
            );
            document.querySelector("#planes .controls button").addEventListener(
                "click",
                function (ev) {
                    reset_checkboxes(plane_checkboxes);
                    var new_planes = random_choice(planes, 3);
                    var render_windows = document.getElementById("planes").getElementsByClassName("render_window");
                    Array.prototype.forEach.call(render_windows, function (r) {r.innerHTML = "";});
                    plane_control = show_group(
                        render_windows,
                        new_planes,
                        5
                    );
                }
            );
        </script>
        <script>
            // Make the carousel for the comparisons
            var glide1 = new Glide(".glide1", {
                type: "carousel",
                startAt: 0,
                perView: 1,
                autoplay: 4000
            }).mount();
        </script>
        <script>
            // Make the carousel for the comparisons
            var glide2 = new Glide(".glide2", {
                type: "carousel",
                startAt: 0,
                perView: 1,
                autoplay: 4000
            }).mount();
        </script>
        <script>
            // Make the carousel for the comparisons
            var glide3 = new Glide(".glide3", {
                type: "carousel",
                startAt: 0,
                perView: 1,
                autoplay: 4000
            }).mount();
        </script>
    </body>
</html>
